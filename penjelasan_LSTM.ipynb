{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.4-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "penjelasan_LSTM.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachmadAgungP/Data/blob/master/penjelasan_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZPPed6JDcUr",
        "colab_type": "text"
      },
      "source": [
        "# Class LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELc4bfRX7Mw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class LSTMCell: \n",
        "    # numCells = ukuran penampungan I,o,z,dll\n",
        "    # Size is the dimensionality of the input vector\n",
        "    def __init__(self, inputSize, numCells, W):\n",
        "        self.inputSize = inputSize\n",
        "        self.numCells = numCells\n",
        "\n",
        "        # Randomly initialise the weight matrix\n",
        "        # self.W = np.random.random((4 * numCells, inputSize + numCells)) * 2 \\\n",
        "        #                 - np.ones((4 * numCells, inputSize + numCells))\n",
        "        \n",
        "        self.W = W\n",
        "        \n",
        "        W = pd.DataFrame(self.W)\n",
        "        #bobot disimpan .csv\n",
        "        W.to_csv(\"P_W.csv\",header=False,index=False) \n",
        "        #pemanggilan .csv\n",
        "        # weight = pd.read_csv('P_W.csv')\n",
        "        # weight = weight.values.tolist()\n",
        "        # weighting = np.array(weight)\n",
        "        # self.W = weighting\n",
        "                    \n",
        "        self.h = []\n",
        "        self.C = []\n",
        "        self.C_bar = []\n",
        "        self.i = []\n",
        "        self.f = []\n",
        "        self.o = []\n",
        "\n",
        "        self.I = []\n",
        "        self.z = []\n",
        "\n",
        "    # x is the input vector (including bias term), returns output h\n",
        "    def forwardStep(self, x):\n",
        "       \n",
        "        I = np.concatenate((x, self.h[-1])) #mengabungkan\n",
        "        self.I.append(I) \n",
        "        z = np.dot(self.W, I)\n",
        "        self.z.append(z)\n",
        "        # Compute the candidate value vector\n",
        "        C_bar = np.tanh(z[0:self.numCells])\n",
        "        self.C_bar.append(C_bar)\n",
        "        # Compute input gate vector\n",
        "        i = sigmoid(z[self.numCells:self.numCells * 2])\n",
        "        self.i.append(i)\n",
        "        # Compute forget gate vector\n",
        "        f = sigmoid(z[self.numCells * 2:self.numCells * 3])\n",
        "        self.f.append(f)\n",
        "        # Compute the output gate vector\n",
        "        o = sigmoid(z[self.numCells * 3:])\n",
        "        self.o.append(o)\n",
        "        # Compute the new state vector as the elements of the old state allowed\n",
        "        # through by the forget gate, plus the candidate values allowed through\n",
        "        # by the input gate\n",
        "        C = np.multiply(f, self.C[-1]) + np.multiply(i, C_bar)\n",
        "        self.C.append(C)\n",
        "        # Compute the new output\n",
        "        h = np.multiply(o, np.tanh(C))\n",
        "        self.h.append(h)\n",
        "        \n",
        "        return (h,C,o,f,i,C_bar,z,I,self.W)\n",
        "    # x = trainingSequences (data training)\n",
        "    def forwardPass(self, x):\n",
        "        \n",
        "        self.h = []\n",
        "        self.C = []\n",
        "        self.C_bar = []\n",
        "        self.i = []\n",
        "        self.f = []\n",
        "        self.o = []\n",
        "\n",
        "        self.I = []\n",
        "        self.z = []\n",
        "        \n",
        "        numCells = self.numCells \n",
        "        \n",
        "        self.h.append(np.zeros(numCells)) # initial output is empty\n",
        "        \n",
        "        self.C.append(np.zeros(numCells)) # initial state is empty\n",
        "        \n",
        "        self.C_bar.append(np.zeros(numCells)) # this and the following\n",
        "        \n",
        "        # empty arrays make the indexing follow the indexing in papers\n",
        "        self.i.append(np.zeros(numCells)) \n",
        "        self.f.append(np.zeros(numCells)) \n",
        "        self.o.append(np.zeros(numCells)) \n",
        "        self.I.append(np.zeros(numCells)) \n",
        "        self.z.append(np.zeros(numCells)) \n",
        "    \n",
        "        O_W= []\n",
        "        O_I= []\n",
        "        O_z= []\n",
        "        O_c= []\n",
        "        O_o= []\n",
        "        O_f= []\n",
        "        O_in= []\n",
        "        O_c_bar= []\n",
        "        O_h = []\n",
        "        \n",
        "        for x_t in x:\n",
        "            w = self.forwardStep(x_t)\n",
        "            O_W.append(w[8])    \n",
        "            O_I.append(w[7])    \n",
        "            O_z.append(w[6])    \n",
        "            O_c.append(w[1])    \n",
        "            O_o.append(w[2])    \n",
        "            O_f.append(w[3])    \n",
        "            O_in.append(w[4])   \n",
        "            O_c_bar.append(w[5])\n",
        "            O_h.append(w[0])    \n",
        "        \n",
        "        # print(O_h)\n",
        "        return (O_I,O_z,O_c,O_o,O_f,O_in,O_c_bar,O_h,O_W)\n",
        "\n",
        "    def backwardStep(self, t, dE_dh_t, dE_dc_tplus1):\n",
        "        dE_do_t = np.multiply(dE_dh_t, np.tanh(self.C[t]))\n",
        "        #print(\"-----------------------------------------\")\n",
        "        dE_dc_t = dE_dc_tplus1 + np.multiply(np.multiply(dE_dh_t, self.o[t]), (np.ones(self.numCells) - np.square(np.tanh(self.C[t]))))\n",
        "        dE_di_t = np.multiply(dE_dc_t, self.C_bar[t])\n",
        "        dE_dcbar_t = np.multiply(dE_dc_t, self.i[t])\n",
        "        dE_df_t = np.multiply(dE_dc_t, self.C[t - 1])\n",
        "        dE_dc_tminus1 = np.multiply(dE_dc_t, self.f[t])\n",
        "        \n",
        "        dE_dzcbar_t = np.multiply(dE_dcbar_t, (np.ones(self.numCells) - np.square(np.tanh(self.z[t][0:self.numCells]))))\n",
        "        dE_dzi_t = np.multiply(np.multiply(dE_di_t, self.i[t]), (np.ones(self.numCells) - self.i[t]))\n",
        "        dE_dzf_t = np.multiply(np.multiply(dE_df_t, self.f[t]), (np.ones(self.numCells) - self.f[t]))\n",
        "        dE_dzo_t = np.multiply(np.multiply(dE_do_t, self.o[t]), (np.ones(self.numCells) - self.o[t]))\n",
        "        dE_dz_t = np.concatenate((dE_dzcbar_t, dE_dzi_t, dE_dzf_t, dE_dzo_t))\n",
        "        dE_dI_t = np.dot(np.transpose(self.W), dE_dz_t)\n",
        "        dE_dh_tminus1 = dE_dI_t[self.inputSize:]\n",
        "        dE_dz_t.shape = (len(dE_dz_t), 1)\n",
        "        self.I[t].shape = (len(self.I[t]), 1)\n",
        "        dE_dW_t = np.dot(dE_dz_t, np.transpose(self.I[t])) # this one is confusing cos it says X_t instead of I_t, but there is no matrix or vector X,\n",
        "        # and the matrix dimensions are correct if we use I instead\n",
        "        # r = pd.DataFrame(dE_dW_t)\n",
        "        # r.to_csv('dE_dW_t%s.csv'%t)\n",
        "        return (dE_dW_t, dE_dh_tminus1, dE_dc_tminus1, dE_do_t, dE_dc_t, dE_di_t, dE_dcbar_t,dE_df_t,dE_dzcbar_t,dE_dzi_t,dE_dzf_t,dE_dzo_t,dE_dz_t,dE_dI_t)\n",
        "    # Back propagation through time, returns the error and the gradient for this sequence\n",
        "    # (should I give this the sequence x1,x2,... so that this method is tied\n",
        "    # to the sequence?)\n",
        "    def BPTT(self, y):\n",
        "        numTimePeriods = len(y)\n",
        "        dE_dW = 0 \n",
        "        dE_dh_t = 0\n",
        "        dE_dc_t = 0\n",
        "        E = 0.0\n",
        "        discount = 1.0\n",
        "        dE_dW_t_list= []\n",
        "        dE_dh_tminus1_list= []\n",
        "        dE_dc_tminus1_list= []\n",
        "        dE_do_t_list= []\n",
        "        dE_dc_t_list= []\n",
        "        dE_di_t_list= []\n",
        "        dE_dcbar_t_list= []\n",
        "        dE_df_t_list= []\n",
        "        dE_dzcbar_t_list= []\n",
        "        dE_dzi_t_list= []\n",
        "        dE_dzf_t_list= []\n",
        "        dE_dzo_t_list= []\n",
        "        dE_dz_t_list= []\n",
        "        dE_dI_t_list= []\n",
        "\n",
        "        dE_dh_tplus1_list= []\n",
        "        dE_dc_tplus1_list= []\n",
        "\n",
        "        dE_dW_list = []\n",
        "        error_list = []  \n",
        "        for i in range(numTimePeriods):\n",
        "            index = numTimePeriods - i\n",
        "            E = E + 0.5 * np.sum(np.absolute(self.h[index] - y[index - 1])) # This is the error/loss vector for this sequence\n",
        "            error_list.append(E)\n",
        "            # The gradient is just 1 or -1, depending on whether h is\n",
        "            # less than or greater than y\n",
        "            lessThan = np.less(self.h[index], y[index - 1])\n",
        "            greaterThan = np.greater(self.h[index], y[index - 1])\n",
        "            dE_dh_t -= 0.5 * lessThan\n",
        "            dE_dh_t += 0.5 * greaterThan\n",
        "            dE_dh_tplus1_list.append(dE_dh_t)\n",
        "            dE_dc_tplus1_list.append(dE_dc_t)\n",
        "            #dE_dh_t += self.h[index] - y[index - 1] # This is the error gradient for this sequence\n",
        "            result = self.backwardStep(index, dE_dh_t, dE_dc_t) \n",
        "            dE_dW = dE_dW + result[0] # dE_dW_t\n",
        "            dE_dW_list.append(dE_dW)\n",
        "\n",
        "            dE_dh_t = result[1]\n",
        "            dE_dc_t = result[2]\n",
        "\n",
        "            dE_dW_t_list.append(result[0])\n",
        "            dE_dh_tminus1_list.append(dE_dh_t)\n",
        "            dE_dc_tminus1_list.append(dE_dc_t)\n",
        "            dE_do_t_list.append(result[3])\n",
        "            dE_dc_t_list.append(result[4])\n",
        "            dE_di_t_list.append(result[5])\n",
        "            dE_dcbar_t_list.append(result[6])\n",
        "            dE_df_t_list.append(result[7])\n",
        "            dE_dzcbar_t_list.append(result[8])\n",
        "            dE_dzi_t_list.append(result[9])\n",
        "            dE_dzf_t_list.append(result[10])\n",
        "            dE_dzo_t_list.append(result[11])\n",
        "            dE_dz_t_list.append(result[12])\n",
        "            dE_dI_t_list.append(result[13])\n",
        "            # discount *= 0.99\n",
        "            \n",
        "        return (E / (numTimePeriods), dE_dW, dE_dW_t_list, dE_dh_tminus1_list, dE_dc_tminus1_list, dE_do_t_list, dE_dc_t_list, dE_di_t_list, dE_dcbar_t_list, dE_df_t_list, dE_dzcbar_t_list, dE_dzi_t_list, dE_dzf_t_list, dE_dzo_t_list, dE_dz_t_list, dE_dI_t_list, dE_dh_tplus1_list, dE_dc_tplus1_list, dE_dW_list)\n",
        "    def forecast(self,forecastingData):\n",
        "        forward = self.forwardPass(forecastingData)\n",
        "        f_l = np.transpose(np.transpose(forward[0]))\n",
        "        f_z = np.transpose(np.transpose(forward[1]))\n",
        "        f_c = np.transpose(np.transpose(forward[2]))\n",
        "        f_o = np.transpose(np.transpose(forward[3]))\n",
        "        f_f = np.transpose(np.transpose(forward[4]))\n",
        "        f_i = np.transpose(np.transpose(forward[5]))\n",
        "        f_c_bar = np.transpose(np.transpose(forward[6]))\n",
        "        f_h = np.transpose(np.transpose(forward[7]))\n",
        "        f_W = np.transpose(np.transpose(forward[8]))\n",
        "        return (f_h[-1],f_l,f_z,f_c,f_o,f_f,f_i,f_c_bar,f_h,f_W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65iVN2rS-OUu",
        "colab_type": "text"
      },
      "source": [
        "# Fungsi - fungsi "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUrkKcrYChrW",
        "colab_type": "text"
      },
      "source": [
        "## FUNGSI Menampilkan hitungan manual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8d4AAB27MxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_hitung_manual(jenis_proses,data_t,kon):\n",
        "    if jenis_proses == \"forward\":\n",
        "        print (\"PROSES FORWARD\")\n",
        "        if (kon == \"I\" or kon == \"Z\" or kon == \"W\"):\n",
        "            view = pd.DataFrame(data=data_t[kon].tolist(),columns=[\"C\",\"i\",\"f\",\"o\"]).T\n",
        "            return(view)\n",
        "        else:\n",
        "            view = pd.DataFrame(data=data_t[kon].tolist(),columns=[i]).T\n",
        "            return(view)\n",
        "    elif jenis_proses == \"backward\":\n",
        "        print (\"PROSES BACKWARD\")\n",
        "        if kon == \"dE_dW_t\" or kon == \"dE_dW_list\":\n",
        "            view = pd.DataFrame(data=data_t[kon].tolist(),columns=[\"C\",\"i\",\"f\",\"o\"]).T\n",
        "            return(view)\n",
        "        elif kon == \"dE_dz_t\":\n",
        "            view = pd.DataFrame(data=data_t[kon].tolist(),columns=[\"dE_dzcbar_t\", \"dE_dzi_t\", \"dE_dzf_t\", \"dE_dzo_t\"]).T\n",
        "            return(view)\n",
        "        elif kon == \"dE_dI_t\":\n",
        "            view = pd.DataFrame(data=data_t[kon].tolist(),columns=[\"bias\", \"date\", \"x(close)\", \"h(Close)\"]).T\n",
        "            return(view)\n",
        "        else:\n",
        "            view = pd.DataFrame(data=data_t[kon].tolist(),columns=[kon]).T\n",
        "            return(view)\n",
        "    else:\n",
        "        view = pd.DataFrame(data=data_t[kon].tolist(),columns=[kon]).T\n",
        "        return(view)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHsT9exS7MxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tampung_hitung_manual(jenis_proses,data):\n",
        "    if jenis_proses == \"forward\": \n",
        "        var_hidden_layer = data\n",
        "        list_table_hitung_str = [\"I\",\"Z\",\"C\",\"O\",\"F\",\"I_in\",\"C_bar\",\"h\",\"W\"]\n",
        "    elif jenis_proses == \"backward\":\n",
        "        var_hidden_layer = data\n",
        "        list_table_hitung_str = [\"dE_dW_t\", \"dE_dh_tminus1\", \"dE_dc_tminus1\", \"dE_do_t\", \"dE_dc_t\", \"dE_di_t\", \"dE_dcbar_t\", \"dE_df_t\",\"dE_dzcbar_t\",\"dE_dzi_t\",\"dE_dzf_t\",\"dE_dzo_t\",\"dE_dz_t\",\"dE_dI_t\", \"dE_dh_tplus1\", \"dE_dc_tplus1\",\"dE_dW\"]\n",
        "    else:\n",
        "        var_hidden_layer = data\n",
        "        list_table_hitung_str = [\"W\"]\n",
        "\n",
        "    data_full = {}\n",
        "    data_perhitungan = pd.DataFrame(data_full) \n",
        "    vel_hidden_layer = []\n",
        "    count = 0\n",
        "    for i in var_hidden_layer:\n",
        "        data_perhitungan.insert(count, list_table_hitung_str[count],np.transpose(np.transpose(i)).tolist(), True) \n",
        "        count += 1\n",
        "    return data_perhitungan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk_a_zVw7Mwc",
        "colab_type": "text"
      },
      "source": [
        "## FUNGSI Generator untuk memotong data sesuai squencial "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phzXHm4x7Mwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def sequenceProducer(trainingData, sequenceLength):\n",
        "    indices = [i for i in range(0, trainingData.shape[0] - sequenceLength + 1, sequenceLength)]\n",
        "    #random.shuffle(indices)\n",
        "    for index in indices:\n",
        "        yield trainingData[index:index + sequenceLength]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE-4I0rTVVXw",
        "colab_type": "code",
        "outputId": "b98ec005-e4ae-43af-9046-0f2f1ccc399c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "a = []\n",
        "for r in range(1,100):\n",
        "    a.append([])\n",
        "    a[r-1].append(r)\n",
        "c = np.array(a)\n",
        "b = sequenceProducer(c, 5)\n",
        "for t in range(1,20):\n",
        "  print (next(b))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]]\n",
            "[[ 6]\n",
            " [ 7]\n",
            " [ 8]\n",
            " [ 9]\n",
            " [10]]\n",
            "[[11]\n",
            " [12]\n",
            " [13]\n",
            " [14]\n",
            " [15]]\n",
            "[[16]\n",
            " [17]\n",
            " [18]\n",
            " [19]\n",
            " [20]]\n",
            "[[21]\n",
            " [22]\n",
            " [23]\n",
            " [24]\n",
            " [25]]\n",
            "[[26]\n",
            " [27]\n",
            " [28]\n",
            " [29]\n",
            " [30]]\n",
            "[[31]\n",
            " [32]\n",
            " [33]\n",
            " [34]\n",
            " [35]]\n",
            "[[36]\n",
            " [37]\n",
            " [38]\n",
            " [39]\n",
            " [40]]\n",
            "[[41]\n",
            " [42]\n",
            " [43]\n",
            " [44]\n",
            " [45]]\n",
            "[[46]\n",
            " [47]\n",
            " [48]\n",
            " [49]\n",
            " [50]]\n",
            "[[51]\n",
            " [52]\n",
            " [53]\n",
            " [54]\n",
            " [55]]\n",
            "[[56]\n",
            " [57]\n",
            " [58]\n",
            " [59]\n",
            " [60]]\n",
            "[[61]\n",
            " [62]\n",
            " [63]\n",
            " [64]\n",
            " [65]]\n",
            "[[66]\n",
            " [67]\n",
            " [68]\n",
            " [69]\n",
            " [70]]\n",
            "[[71]\n",
            " [72]\n",
            " [73]\n",
            " [74]\n",
            " [75]]\n",
            "[[76]\n",
            " [77]\n",
            " [78]\n",
            " [79]\n",
            " [80]]\n",
            "[[81]\n",
            " [82]\n",
            " [83]\n",
            " [84]\n",
            " [85]]\n",
            "[[86]\n",
            " [87]\n",
            " [88]\n",
            " [89]\n",
            " [90]]\n",
            "[[91]\n",
            " [92]\n",
            " [93]\n",
            " [94]\n",
            " [95]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imcxVgBV7Mwm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcAvB2iZ7Mwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forecastSequenceProducer(trainingData, sequenceLength):\n",
        "    for i in range(trainingData.shape[0] - sequenceLength + 1):\n",
        "        yield trainingData[i:i + sequenceLength]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Yc61jR7Mwu",
        "colab_type": "text"
      },
      "source": [
        "c = []\n",
        "for r in range(1,100):\n",
        "    c.append(r)\n",
        "\n",
        "d = forecastSequenceProducer(c, 5)\n",
        "for t in range(1,20):\n",
        "    print (next(d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp5Cvjto-ZA_",
        "colab_type": "text"
      },
      "source": [
        "## FUNGSI readdata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGismFSs-J-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "\n",
        "\n",
        "def readData(filename):\n",
        "    data = pd.read_csv(io.StringIO(filename.decode('utf-8')))\n",
        "\n",
        "    data = data[['Date','Close']]\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "    data1 = data[['Date','Close']]\n",
        "    data1['Date'] = pd.to_datetime(data['Date'])\n",
        "    s1 = data1.values.tolist()\n",
        "    # data1.insert(0, \"subject_index\",0) \n",
        "    # ex_csv1 = pd.DataFrame(data1)\n",
        "    # ex_csv1.to_csv(\"SMGRW.csv\")\n",
        "\n",
        "    data['Date'] =  data['Date'].dt.strftime(\"%Y%m%d\").astype(int)\n",
        "\n",
        "    s = data.values.tolist()\n",
        "    training_data  = np.array(s)\n",
        "\n",
        "    min_ex = np.amin(training_data, axis=0)\n",
        "    max_ex = np.amax(training_data, axis=0)\n",
        "    original_data = np.copy(training_data)\n",
        "    training_data -= min_ex\n",
        "    training_data /= max_ex\n",
        "    tbl_data = pd.DataFrame(data=training_data,columns=[\"date\",\"x(close)\"])\n",
        "    min_data = pd.DataFrame(data=min_ex,columns=[0]).T\n",
        "    max_data = pd.DataFrame(data=max_ex,columns=[1]).T\n",
        "    frame = [min_data,max_data]\n",
        "    tbl_min_max = pd.concat(frame)\n",
        "    tbl_min_max = tbl_min_max.rename(columns={0:\"data\",1:\"x(close)\"},index={0:\"max\",1:\"min\"})\n",
        "    return (training_data, max_ex, min_ex, original_data,tbl_data,tbl_min_max)\n",
        "    \n",
        "def bagi_data(skenario,data_sa):\n",
        "    if (skenario == 1):\n",
        "        trainingData = data_sa[:-250]\n",
        "        forecastData = data_sa[250:500]\n",
        "    elif (skenario == 2):\n",
        "        trainingData = data_sa[:-500]\n",
        "        forecastData = data_sa[500:1000]\n",
        "    elif (skenario == 5):\n",
        "        trainingData = data_sa[:7]\n",
        "        forecastData = data_sa[5:10]\n",
        "    else :\n",
        "        trainingData = data_sa[:-1000]\n",
        "        forecastData = data_sa[500:-500]\n",
        "    return (trainingData, forecastData)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmwRo9q87Mvy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Membaca data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOFh6trG7Mv-",
        "colab_type": "code",
        "outputId": "bc2e2964-db5b-4de6-81dd-99e7ad4e8f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import pandas as pd\n",
        "DataSahamStr = 'ujicoba.csv'\n",
        "url_data = \"https://raw.githubusercontent.com/RachmadAgungP/Data/master/ujicoba.csv\" \n",
        "data = requests.get(url_data).content\n",
        "\n",
        "data = readData(data)\n",
        "tbl_data = data[4]\n",
        "tbl_min_max = data[5]\n",
        "\n",
        "print (\"- tabel data normalisasi -\")\n",
        "print (tbl_data)\n",
        "print ()\n",
        "print (\"-- tabel data min max --\")\n",
        "print (tbl_min_max)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- tabel data normalisasi -\n",
            "           date  x(close)\n",
            "0  0.000000e+00  0.030303\n",
            "1  4.965213e-08  0.020202\n",
            "2  1.986085e-07  0.026263\n",
            "3  2.979128e-07  0.018182\n",
            "4  3.475649e-07  0.000000\n",
            "5  3.972170e-07  0.016162\n",
            "6  5.461734e-07  0.026263\n",
            "7  5.958256e-07  0.022222\n",
            "8  6.454777e-07  0.024242\n",
            "9  6.951298e-07  0.000000\n",
            "\n",
            "-- tabel data min max --\n",
            "           data  x(close)\n",
            "max  20140109.0   12000.0\n",
            "min  20140123.0   12375.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f5xHP737MwE",
        "colab_type": "text"
      },
      "source": [
        "# Inisial variable untuk input LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Hh_t977MwE",
        "colab_type": "code",
        "outputId": "9d4016bc-5b9f-4acf-d111-9a463a3e4369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# I_SequenceLength = int(input(\"masukkan panjang memory: \"))\n",
        "I_SequenceLength = 5\n",
        "print (\"Panjang memory(sequenceLength) adalah %s\" %I_SequenceLength)\n",
        "sequenceLength = I_SequenceLength\n",
        "\n",
        "# numEpochs = int(input(\"masukkan banyak epoch : \"))\n",
        "numEpochs = 1\n",
        "print (\"banyak epoch adalah %s\" %numEpochs)\n",
        "\n",
        "data_saham_Normalisasi = data[0]\n",
        "\n",
        "# rate = float(input(\"masukkan learning rate : \"))\n",
        "rate = 0.1\n",
        "print (\"Learnig rate adalah %s\" %rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Panjang memory(sequenceLength) adalah 5\n",
            "banyak epoch adalah 1\n",
            "Learnig rate adalah 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECQiBFpF7MwL",
        "colab_type": "text"
      },
      "source": [
        "# Persiapan Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DSXiRPC7MwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# menambhakan data 1 atau bias \n",
        "data_saham_Normalisasi = np.concatenate((np.ones((data_saham_Normalisasi.shape[0], 1)), data_saham_Normalisasi), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hFNWDfn7MwV",
        "colab_type": "code",
        "outputId": "74db829e-066d-4038-c74b-8047f1e2d73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# skenarioI = int(input(\"masukkan skenario pilihan : \"))\n",
        "skenarioI = 5\n",
        "\n",
        "# sebelum digabungkan 1 = [0.00000000e+00 4.32551320e-01]\n",
        "import numpy as np\n",
        "# setelah digabungkan 1 = [1.00000000e+00 0.00000000e+00 4.32551320e-01]\n",
        "# pembagian skenario\n",
        "skenarioP = bagi_data(skenarioI,data_saham_Normalisasi)\n",
        "print (\"banyak data training : \",len(skenarioP[0]))\n",
        "training_Data = skenarioP[0]\n",
        "tbl_data_training = pd.DataFrame(data=training_Data,columns=[\"bias\",\"date\",\"x(close)\"])\n",
        "print (tbl_data_training)\n",
        "print (data_saham_Normalisasi.shape[0])\n",
        "print (\"banyak data testing : \",len(skenarioP[1]))\n",
        "testing_Data = skenarioP[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "banyak data training :  7\n",
            "   bias          date  x(close)\n",
            "0   1.0  0.000000e+00  0.030303\n",
            "1   1.0  4.965213e-08  0.020202\n",
            "2   1.0  1.986085e-07  0.026263\n",
            "3   1.0  2.979128e-07  0.018182\n",
            "4   1.0  3.475649e-07  0.000000\n",
            "5   1.0  3.972170e-07  0.016162\n",
            "6   1.0  5.461734e-07  0.026263\n",
            "10\n",
            "banyak data testing :  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3eYNI-xDxrs",
        "colab_type": "text"
      },
      "source": [
        "## CALL LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ktc6pL37Mw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = LSTMCell(inputSize, numCells,W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb2GVZ-y7Mwv",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSou7-ZS7Mww",
        "colab_type": "code",
        "outputId": "ccf625a7-add2-4ae6-c00b-89d887b117d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "inputSize = data_saham_Normalisasi.shape[1]\n",
        "numCells = data_saham_Normalisasi.shape[1]-2\n",
        "W = [[-0.245714286\t,0.850360602\t,0.029262045\t,0.184398087]\n",
        "        ,[0.868020398\t,0.860429754\t,-0.379580925\t,0.079506914]\n",
        "        ,[-0.206444161\t,-0.24856166\t,-0.085253247\t,0.25112624\t]\n",
        "        ,[0.842874383\t,-0.324206065\t,0.907722829\t,-0.593738792]]\n",
        "\n",
        "mtrx_w = pd.DataFrame(data=W,index=[\"C\",\"i\",\"f\",\"o\"], columns=[\"bias\",\"date\",\"x(close)\",\"h(close)\"])\n",
        "\n",
        "print (\"Ukuran Input \",inputSize)\n",
        "print (\"Ukuran Output \",numCells)\n",
        "print (\"Ukuran bobot \",len(W))\n",
        "print (\"-------------- matriks bobot ------------\")\n",
        "print (mtrx_w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ukuran Input  3\n",
            "Ukuran Output  1\n",
            "Ukuran bobot  4\n",
            "-------------- matriks bobot ------------\n",
            "       bias      date  x(close)  h(close)\n",
            "C -0.245714  0.850361  0.029262  0.184398\n",
            "i  0.868020  0.860430 -0.379581  0.079507\n",
            "f -0.206444 -0.248562 -0.085253  0.251126\n",
            "o  0.842874 -0.324206  0.907723 -0.593739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d798sI7Cy8j",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "e_1lOTF-7MxP",
        "colab_type": "code",
        "outputId": "2763271c-0ca5-4217-b919-9d01cc1db0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "import pandas as pd\n",
        "adaptiveLearningRate = rate\n",
        "\n",
        "data_perhitungan_training_csv = {}\n",
        "data_perhitungan_training = pd.DataFrame(data_perhitungan_training_csv) # df \n",
        "\n",
        "data_perhitungan_training_BPTT_csv = {}\n",
        "data_perhitungan_training_BPTT = pd.DataFrame(data_perhitungan_training_BPTT_csv) # df \n",
        "\n",
        "data_perhitungan_training_optimasi_csv = {}\n",
        "data_perhitungan_training_optimasi = pd.DataFrame(data_perhitungan_training_optimasi_csv) # df \n",
        "\n",
        "for epoch in range(numEpochs):\n",
        "    trainingSequences = sequenceProducer(training_Data, sequenceLength) #data training \n",
        "    epochError = 0.0\n",
        "    counter = 0\n",
        "    for sequence in trainingSequences:\n",
        "        counter += 1\n",
        "        # proses forward\n",
        "        forecast_h = lstm.forwardPass(sequence[:-1])\n",
        "        print (\"forecast_h\",forecast_h)\n",
        "        froward = [forecast_h[0],forecast_h[1],forecast_h[2],forecast_h[3],forecast_h[4],forecast_h[5],forecast_h[6],forecast_h[7],forecast_h[8]]\n",
        "        # melihat hasil perhitungan secara detail \n",
        "        data_perhitungan_new_training = tampung_hitung_manual(\"forward\",froward)\n",
        "\n",
        "        data_perhitungan_training = pd.concat([data_perhitungan_new_training, data_perhitungan_training]).reset_index(drop = True) \n",
        "        # --------------------------------------------------------------------------\n",
        "\n",
        "        # proses backward \n",
        "        result = lstm.BPTT(sequence[1:,2:])\n",
        "        backward = [result[2],result[3],result[4],result[5],result[6],result[7],result[8],result[9],result[10],result[11],result[12],result[13],result[14],result[15],result[16],result[17],result[18]]\n",
        "        # melihat hasil perhitungan secara detail \n",
        "        data_perhitungan_new_training_BPTT = tampung_hitung_manual(\"backward\",backward)\n",
        "\n",
        "        data_perhitungan_training_BPTT = pd.concat([data_perhitungan_new_training_BPTT, data_perhitungan_training_BPTT]).reset_index(drop = True) \n",
        "        # # hasil error yang dihasilkan backword\n",
        "        E = result[0]\n",
        "        print (\"E\",E)\n",
        "        # hasil turunan bobot dihasilkan backword\n",
        "        dE_dW = result[1]\n",
        "        w = dE_dW.shape\n",
        "        \n",
        "        # Annealing () Optimasi\n",
        "        adaptiveLearningRate = rate / (1 + (epoch/10))\n",
        "        lstm.W = lstm.W - adaptiveLearningRate * dE_dW\n",
        "        print (pd.DataFrame(list(W)))\n",
        "        r = [list(w)]\n",
        "        epochError += E\n",
        "        \n",
        "    # for = [\"I\",\"Z\",\"C\",\"O\",\"F\",\"I_in\",\"C_bar\",\"h\",\"W\"]\n",
        "    # back = [\"dE_dW_t\", \"dE_dh_tminus1\", \"dE_dc_tminus1\", \"dE_do_t\", \"dE_dc_t\", \"dE_di_t\", \"dE_dcbar_t\", \"dE_df_t\",\"dE_dzcbar_t\",\"dE_dzi_t\",\"dE_dzf_t\",\"dE_dzo_t\",\"dE_dz_t\",\"dE_dI_t\",\"dE_dh_tplus1\", \"dE_dc_tplus1\"]\n",
        "    print('Epoch ' + str(epoch) + ' error: ' + str(epochError / counter))\n",
        "    print (view_hitung_manual(\"forward\",data_perhitungan_training,\"I\"))\n",
        "    print (view_hitung_manual(\"backward\",data_perhitungan_training_BPTT,\"dE_dc_tminus1\"))\n",
        "    data_perhitungan_training_BPTT.to_csv(\"perhitungan_bbpt.csv\")\n",
        "    data_perhitungan_training.to_csv(\"perhitungan_training.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forecast_h ([array([1.        , 0.        , 0.03030303, 0.        ]), array([ 1.00000000e+00,  4.96521297e-08,  2.02020202e-02, -1.17651092e-01]), array([ 1.00000000e+00,  1.98608519e-07,  2.62626263e-02, -1.80354973e-01]), array([ 1.00000000e+00,  2.97912778e-07,  1.81818182e-02, -2.12725368e-01]), array([ 1.00000000e+00,  3.47564908e-07,  0.00000000e+00, -2.28708352e-01]), array([ 1.00000000e+00,  3.97217038e-07,  1.61616162e-02, -2.36390528e-01])], [array([-0.24482756,  0.85651795, -0.20902759,  0.87038114]), array([-0.26681773,  0.85099806, -0.23771174,  0.93106622]), array([-0.27820273,  0.84371231, -0.25397505,  0.97379725]), array([-0.28440815,  0.84420605, -0.26141522,  0.98568164]), array([-0.28788737,  0.8498368 , -0.26387892,  0.97866729]), array([-0.28883099,  0.84309142, -0.26718595,  0.99789875])], [array([-0.16849919]), array([-0.25694819]), array([-0.30191084]), array([-0.32504204]), array([-0.3374834]), array([-0.34282462])], [array([0.704825]), array([0.71729155]), array([0.72587572]), array([0.72823412]), array([0.7268437]), array([0.73064525])], [array([0.44793254]), array([0.44085033]), array([0.43684535]), array([0.43501585]), array([0.43441042]), array([0.43359807])], [array([0.70193264]), array([0.70077647]), array([0.69924649]), array([0.69935032]), array([0.70053291]), array([0.6991159])], [array([-0.24005037]), array([-0.26066125]), array([-0.27124085]), array([-0.27697999]), array([-0.28018919]), array([-0.2810585])], [array([-0.11765109]), array([-0.18035497]), array([-0.21272537]), array([-0.22870835]), array([-0.23639053]), array([-0.24111056])], [[[-0.245714286, 0.850360602, 0.029262045, 0.184398087], [0.868020398, 0.860429754, -0.379580925, 0.079506914], [-0.206444161, -0.24856166, -0.085253247, 0.25112624], [0.842874383, -0.324206065, 0.907722829, -0.593738792]], [[-0.245714286, 0.850360602, 0.029262045, 0.184398087], [0.868020398, 0.860429754, -0.379580925, 0.079506914], [-0.206444161, -0.24856166, -0.085253247, 0.25112624], [0.842874383, -0.324206065, 0.907722829, -0.593738792]], [[-0.245714286, 0.850360602, 0.029262045, 0.184398087], [0.868020398, 0.860429754, -0.379580925, 0.079506914], [-0.206444161, -0.24856166, -0.085253247, 0.25112624], [0.842874383, -0.324206065, 0.907722829, -0.593738792]], [[-0.245714286, 0.850360602, 0.029262045, 0.184398087], [0.868020398, 0.860429754, -0.379580925, 0.079506914], [-0.206444161, -0.24856166, -0.085253247, 0.25112624], [0.842874383, -0.324206065, 0.907722829, -0.593738792]], [[-0.245714286, 0.850360602, 0.029262045, 0.184398087], [0.868020398, 0.860429754, -0.379580925, 0.079506914], [-0.206444161, -0.24856166, -0.085253247, 0.25112624], [0.842874383, -0.324206065, 0.907722829, -0.593738792]], [[-0.245714286, 0.850360602, 0.029262045, 0.184398087], [0.868020398, 0.860429754, -0.379580925, 0.079506914], [-0.206444161, -0.24856166, -0.085253247, 0.25112624], [0.842874383, -0.324206065, 0.907722829, -0.593738792]]])\n",
            "E 0.11033429865897924\n",
            "          0         1         2         3\n",
            "0 -0.245714  0.850361  0.029262  0.184398\n",
            "1  0.868020  0.860430 -0.379581  0.079507\n",
            "2 -0.206444 -0.248562 -0.085253  0.251126\n",
            "3  0.842874 -0.324206  0.907723 -0.593739\n",
            "Epoch 0 error: 0.11033429865897924\n",
            "PROSES FORWARD\n",
            "          0             1  ...             4             5\n",
            "C  1.000000  1.000000e+00  ...  1.000000e+00  1.000000e+00\n",
            "i  0.000000  4.965213e-08  ...  3.475649e-07  3.972170e-07\n",
            "f  0.030303  2.020202e-02  ...  0.000000e+00  1.616162e-02\n",
            "o  0.000000 -1.176511e-01  ... -2.287084e-01 -2.363905e-01\n",
            "\n",
            "[4 rows x 6 columns]\n",
            "PROSES BACKWARD\n",
            "                      0         1         2        3         4         5\n",
            "dE_dc_tminus1 -0.141153 -0.216506 -0.256395 -0.27938 -0.295964 -0.313223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQzh8DCK7MxW",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTDTGZgL7MxW",
        "colab_type": "code",
        "outputId": "dd25ca9a-76fb-45fa-eec3-f678041f5aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "forecastSequences = forecastSequenceProducer(testing_Data, sequenceLength)\n",
        "forecastError = 0.0\n",
        "forecastError_MSE = 0.0\n",
        "forecastError_MAPE = 0.0\n",
        "countForecasts = 0\n",
        "# Data Real\n",
        "labels = []\n",
        "\n",
        "# Data Preiksi\n",
        "forecasts = []\n",
        "max_ex = data[1]\n",
        "min_ex = data[2]\n",
        "\n",
        "data_full_testing_csv = {}\n",
        "data_perhitungan_testing = pd.DataFrame(data_full_testing_csv) # df \n",
        "\n",
        "for sequence in forecastSequences: \n",
        "    countForecasts += 1\n",
        "    forecast_w = lstm.forecast(sequence[:-1])\n",
        "    # print (\"squence predict \",R)\n",
        "    V_Predict = forecast_w[0]\n",
        "    print (V_Predict)\n",
        "    V_Predict *= max_ex[1:]\n",
        "    V_Predict += min_ex[1:]\n",
        "    # data_sequence_close_NT = sequence[:,2:]\n",
        "    # sequenceNT = denormal(sequenceLength,sequence,max_ex,min_ex)\n",
        "\n",
        "    # block proses\n",
        "    forward = [forecast_w[1],forecast_w[2],forecast_w[3],forecast_w[4],forecast_w[5],forecast_w[6],forecast_w[7],forecast_w[8],forecast_w[9]]\n",
        "    # melihat hasil perhitungan secara detail \n",
        "    data_perhitungan_new_testing = tampung_hitung_manual(\"forward\",forward)\n",
        "\n",
        "    data_perhitungan_testing = pd.concat([data_perhitungan_new_testing, data_perhitungan_testing]).reset_index(drop = True) \n",
        "    # ----------------------------------------------------------------------------------\n",
        "\n",
        "    label = sequence[-1,2:] * max_ex[1:]\n",
        "    label += min_ex[1:]\n",
        "\n",
        "    forecasts.append(V_Predict)\n",
        "\n",
        "    labels.append(label)\n",
        "\n",
        "    print('Error: ' + str(np.absolute( label[-1]-V_Predict[-1] )))\n",
        "\n",
        "    forecastError += np.absolute(label[-1]-V_Predict[-1])\n",
        "    \n",
        "    forecastError_MSE += (np.absolute(label[-1]-V_Predict[-1]))**2\n",
        "    \n",
        "    # print_sequence(sequence,max_ex,min_ex)\n",
        "\n",
        "    print ('----------------')\n",
        "\n",
        "data_perhitungan_testing.to_csv(\"datatata.csv\") # block preses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.02090026]\n",
            "Error: 258.6407208763958\n",
            "----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8eyZoDf7Mxa",
        "colab_type": "text"
      },
      "source": [
        "# Hasil Prediksi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "id": "n4QrXtak7Mxa",
        "colab_type": "code",
        "outputId": "5d841cce-ca9f-4cb6-ce67-5f7cf83f750c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# dari dataframe ke array \n",
        "# data prediksi \n",
        "forecasts = np.array(forecasts)\n",
        "\n",
        "# originalData = np.array(originalData) \n",
        "\n",
        "# data real belum \n",
        "labels = np.array(labels)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# memotongan data tiap hari ke 5 \n",
        "times = [i for i in range(forecasts.shape[0])]\n",
        "\n",
        "real = np.array(labels[:,-1])\n",
        "print (\"Real \", len(real))\n",
        "print (real)\n",
        "reali = real.tolist()\n",
        "\n",
        "prediksi = np.array(forecasts[:,-1])\n",
        "print (\"Prediksi \",len(prediksi)) \n",
        "print (prediksi)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real  1\n",
            "[12000.]\n",
            "Prediksi  1\n",
            "[11741.35927912]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CDe4Hte7Mxk",
        "colab_type": "text"
      },
      "source": [
        "# Evaluasi Acuracy, MAPE, MSE, DAN MAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qmJf2QX7Mxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "\n",
        "y_true = np.random.randn(100)\n",
        "y_pred = y_true * 3.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJntBjbl7Mxs",
        "colab_type": "code",
        "outputId": "dc759590-d80a-4cd9-cc00-da85e031d239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Average forecast error: (MAD) = ' + str(forecastError / countForecasts))\n",
        "print('Average forecast error: (MSE) = ' + str(forecastError_MSE / countForecasts))\n",
        "\n",
        "print ('Average forecast error: (MAPE) = ' + str(mean_absolute_percentage_error(reali, prediksi))+\" %\")\n",
        "print ('Average Secore Accuracy: ' + str(100 - mean_absolute_percentage_error(real, prediksi))+\" %\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average forecast error: (MAD) = 258.6407208763958\n",
            "Average forecast error: (MSE) = 66895.02249546167\n",
            "Average forecast error: (MAPE) = 2.1553393406366315 %\n",
            "Average Secore Accuracy: 97.84466065936337 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syVvcc0K7Mxx",
        "colab_type": "text"
      },
      "source": [
        "# Visualisasi hasi perbandingan prediksi dan real "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MAS3pBa7Mxy",
        "colab_type": "code",
        "outputId": "cd61804b-1a03-4e16-e971-5d608cf44de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import pylab as pl\n",
        "pl.plot(times, forecasts, 'r')\n",
        "pl.plot(times, labels[:,-1], 'b')\n",
        "# pl.plot(x,y,'*k')\n",
        "pl.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARKUlEQVR4nO3de4xmdX3H8fdHFraAVi47UGRpdymEBKSh5QlqUg2ClKWxLFKwIMFtpWKi/uMlFUKN9vKHeAnGS2vWsrA1yqU0BBIiyEWyrRd01i6y67IwgsJu0Rm5eIEoLvvtH8+PehxmmdmZZ2YY9v1KTp7zfM/vnP19mWQ+c87vmSFVhSRp9/aS+Z6AJGn+GQaSJMNAkmQYSJIwDCRJwKL5nsB0LVmypJYtWzbf05CkBWX9+vU/qaqh8fUFGwbLli1jeHh4vqchSQtKkh9OVPcxkSTJMJAkGQaSJAwDSRKGgSSJKYZBkjVJRpNs7NQ+luTeJN9Ncn2S/TrHLk4ykmRLklM79RWtNpLkok59eZK7Wv2aJHsNqkFJ0uSmemdwJbBiXO1W4JVV9UfAfcDFAEmOBs4Bjmnn/EuSPZLsAXwWOA04Gji3jQW4FLisqo4AHgcumHZHkqRdNqUwqKp1wGPjal+pqu3t7TeBpW1/JXB1Vf2qqh4ERoAT2jZSVQ9U1dPA1cDKJAFOAq5r568FzphBT5KkXTSoNYO3AV9u+4cCD3eObW21ndUPBJ7oBMuz9edIcmGS4STDY2NjA5q6JGnGYZDkEmA78MWZT+f5VdXqqupVVW9o6Dm/TS1JmqYZ/TmKJH8NvBE4uX7zv0zbBhzWGba01dhJ/VFgvySL2t1Bd7wkaQ5M+84gyQrg74DTq+qpzqEbgXOSLE6yHDgS+BbwbeDI9smhvegvMt/YQuSrwFnt/FXADdOdlyRp1031o6VXAd8AjkqyNckFwGeAlwG3JtmQ5HMAVbUJuBb4HnAz8K6qeqb91P9u4BZgM3BtGwvwAeC9SUboryFcPrAOJUmTym+e7iwsvV6v/KulkrRrkqyvqt74ur+BLEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEliCmGQZE2S0SQbO7Wzk2xKsiNJr1PfK8kVSe5JcneSEzvH7kyyJcmGth3U6ouTXJNkJMldSZYNtENJ0qSmcmdwJbBiXG0jcCawblz97QBVdSxwCvCJJN1/47yqOq5to612AfB4VR0BXAZcumstSJJmatIwqKp1wGPjapurassEw48G7mhjRoEngN4E47pWAmvb/nXAyUky2bwkSYMz6DWDu4HTkyxKshw4Hjisc/yK9ojog51v+IcCDwNU1Xbgp8CBE108yYVJhpMMj42NDXjqkrT7GnQYrAG2AsPAJ4GvA8+0Y+e1x0evbdv5u3rxqlpdVb2q6g0NDQ1oypKkgYZBVW2vqve0NYGVwH7Afe3Ytvb6c+BLwAnttG20u4cki4CXA48Ocl6SpOc30DBIsk+Sfdv+KcD2qvpee2y0pNX3BN5IfxEa4EZgVds/C7ijqmqQ85IkPb9Fkw1IchVwIrAkyVbgQ/QXlD8NDAE3JdlQVacCBwG3JNlB/yf+Zx8FLW71PYE9gNuAz7djlwNfSDLSrnvOgHqTJE3RpGFQVefu5ND1E4z9AXDUBPUn6S8mT3T9XwJnTzYPSdLs8TeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkphAGSdYkGU2ysVM7O8mmJDuS9Dr1vZJckeSeJHcnObFz7PhWH0nyqSRp9QOS3Jrk/va6/4B7lCRNYip3BlcCK8bVNgJnAuvG1d8OUFXHAqcAn0jy7L/xr+34kW179poXAbdX1ZHA7e29JGkOTRoGVbUOeGxcbXNVbZlg+NHAHW3MKPAE0EtyCPC7VfXNqirg34Ez2jkrgbVtf22nLkmaI4NeM7gbOD3JoiTLgeOBw4BDga2dcVtbDeDgqnqk7f8IOHhnF09yYZLhJMNjY2MDnrok7b4GHQZr6H+jHwY+CXwdeGaqJ7e7hnqe46urqldVvaGhoZnOVZLULBrkxapqO/CeZ98n+TpwH/A4sLQzdCmwre3/OMkhVfVIe5w0Osg5SZImN9A7gyT7JNm37Z8CbK+q77XHQD9L8ur2KaK3Aje0024EVrX9VZ26JGmOTHpnkOQq4ERgSZKtwIfoLyh/GhgCbkqyoapOBQ4Cbkmyg/5P/ud3LvVO+p9M2hv4ctsAPgJcm+QC4IfAm2feliRpV6T/mH7h6fV6NTw8PN/TkKQFJcn6quqNr/sbyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkphAGSdYkGU2ysVM7O8mmJDuS9Dr1PZOsTXJPks1JLu4c+0Grb0gy3KkfkOTWJPe31/0H2aAkaXJTuTO4ElgxrrYROBNYN65+NrC4qo4FjgfekWRZ5/jrq+q4qup1ahcBt1fVkcDt7b0kaQ5NGgZVtQ54bFxtc1VtmWg4sG+SRcDewNPAzyb5J1YCa9v+WuCMyeYkSRqsQa8ZXAc8CTwCPAR8vKqeDZICvpJkfZILO+ccXFWPtP0fAQfv7OJJLkwynGR4bGxswFOXpN3XoMPgBOAZ4BXAcuB9SQ5vx/60qv4EOA14V5LXjT+5qop+aEyoqlZXVa+qekNDQwOeuiTtvgYdBm8Bbq6qX1fVKPA1oAdQVdva6yhwPf3gAPhxkkMA2uvogOckSZrEoMPgIeAkgCT7Aq8G7k2yb5KXdep/Rn8RGuBGYFXbXwXcMOA5SZImMZWPll4FfAM4KsnWJBckeVOSrcBrgJuS3NKGfxZ4aZJNwLeBK6rqu/TXAf47yd3At4Cbqurmds5HgFOS3A+8ob2XJM2h9B/TLzy9Xq+Gh4cnHyhJ+n9J1o/7eD/gbyBLkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIkphkGSNUlGk2zs1M5OsinJjiS9Tn3PJGuT3JNkc5KLO8dWJNmSZCTJRZ368iR3tfo1SfYaVIOSpMlN9c7gSmDFuNpG4Exg3bj62cDiqjoWOB54R5JlSfYAPgucBhwNnJvk6HbOpcBlVXUE8Dhwwa42IkmavimFQVWtAx4bV9tcVVsmGg7sm2QRsDfwNPAz4ARgpKoeqKqngauBlUkCnARc185fC5wxnWYkSdMzG2sG1wFPAo8ADwEfr6rHgEOBhzvjtrbagcATVbV9XP05klyYZDjJ8NjY2CxMXZJ2T7MRBicAzwCvAJYD70ty+CAuXFWrq6pXVb2hoaFBXFKSxOyEwVuAm6vq11U1CnwN6AHbgMM645a22qPAfu2xUrcuSZojsxEGD9FfAyDJvsCrgXuBbwNHtk8O7QWcA9xYVQV8FTirnb8KuGEW5iVJ2ompfrT0KuAbwFFJtia5IMmbkmwFXgPclOSWNvyzwEuTbKIfAFdU1XfbmsC7gVuAzcC1VbWpnfMB4L1JRuivIVw+qAYlSZNL/wfzhafX69Xw8PB8T0OSFpQk66uqN77ubyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkphCGCRZk2Q0ycZO7ewkm5LsSNLr1M9LsqGz7UhyXDt2Z5ItnWMHtfriJNckGUlyV5Jlg29TkvR8pnJncCWwYlxtI3AmsK5brKovVtVxVXUccD7wYFVt6Aw579njVTXaahcAj1fVEcBlwKXT6EOSNAOThkFVrQMeG1fbXFVbJjn1XODqKcxhJbC27V8HnJwkUzhPkjQgs7lm8FfAVeNqV7RHRB/sfMM/FHgYoKq2Az8FDpzogkkuTDKcZHhsbGy25i1Ju51ZCYMkrwKeqqqNnfJ5VXUs8Nq2nb+r162q1VXVq6re0NDQgGYrSZqtO4NzGHdXUFXb2uvPgS8BJ7RD24DDAJIsAl4OPDpL85IkTWDgYZDkJcCb6awXJFmUZEnb3xN4I/1FaIAbgVVt/yzgjqqqQc9LkrRziyYbkOQq4ERgSZKtwIfoLyh/GhgCbkqyoapObae8Dni4qh7oXGYxcEsLgj2A24DPt2OXA19IMtKue86Mu5Ik7ZIs1B/Ce71eDQ8Pz/c0JGlBSbK+qnrj6/4GsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQW8N8mSjIG/HC+5zENS4CfzPck5tDu1i/Y8+5iofb8B1X1nP8hzIINg4UqyfBEfyTqxWp36xfseXfxYuvZx0SSJMNAkmQYzIfV8z2BOba79Qv2vLt4UfXsmoEkyTsDSZJhIEnCMJgVSQ5IcmuS+9vr/jsZt6qNuT/JqgmO35hk4+zPeGZm0m+SfZLclOTeJJuSfGRuZ79rkqxIsiXJSJKLJji+OMk17fhdSZZ1jl3c6luSnDqX856J6fac5JQk65Pc015Pmuu5T9dMvs7t+O8n+UWS98/VnGesqtwGvAEfBS5q+xcBl04w5gDggfa6f9vfv3P8TOBLwMb57mc2+wX2AV7fxuwF/Bdw2nz3tJM+9wC+Dxze5no3cPS4Me8EPtf2zwGuaftHt/GLgeXtOnvMd0+z3PMfA69o+68Ets13P7Pdc+f4dcB/AO+f736munlnMDtWAmvb/lrgjAnGnArcWlWPVdXjwK3ACoAkLwXeC/zzHMx1EKbdb1U9VVVfBaiqp4HvAEvnYM7TcQIwUlUPtLleTb/3ru5/i+uAk5Ok1a+uql9V1YPASLveC920e66q/6mq/231TcDeSRbPyaxnZiZfZ5KcATxIv+cFwzCYHQdX1SNt/0fAwROMORR4uPN+a6sB/BPwCeCpWZvhYM20XwCS7Af8BXD7bExyACbtoTumqrYDPwUOnOK5L0Qz6bnrL4HvVNWvZmmegzTtntsPch8A/mEO5jlQi+Z7AgtVktuA35vg0CXdN1VVSab8+d0kxwF/WFXvGf8ccj7NVr+d6y8CrgI+VVUPTG+WeiFKcgxwKfBn8z2XOfBh4LKq+kW7UVgwDINpqqo37OxYkh8nOaSqHklyCDA6wbBtwImd90uBO4HXAL0kP6D/9TkoyZ1VdSLzaBb7fdZq4P6q+uQApjtbtgGHdd4vbbWJxmxtAfdy4NEpnvtCNJOeSbIUuB54a1V9f/anOxAz6flVwFlJPgrsB+xI8suq+szsT3uG5nvR4sW4AR/jtxdUPzrBmAPoP1fcv20PAgeMG7OMhbGAPKN+6a+N/CfwkvnuZZI+F9Ff+F7ObxYWjxk35l389sLitW3/GH57AfkBFsYC8kx63q+NP3O++5irnseN+TALaAF53ifwYtzoPy+9HbgfuK3zTa8H/Ftn3NvoLySOAH8zwXUWShhMu1/6P3UVsBnY0La/ne+enqfXPwfuo/9pk0ta7R+B09v+79D/FMkI8C3g8M65l7TztvAC/cTUIHsG/h54svN13QAcNN/9zPbXuXONBRUG/jkKSZKfJpIkGQaSJAwDSRKGgSQJw0CShGEgScIwkCQB/wfw50/rDB1P2AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Eekint7Mx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}